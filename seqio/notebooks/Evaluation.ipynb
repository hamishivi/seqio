{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXnT83oJWCXI"
      },
      "source": [
        "\n",
        "\u003ca href=\"https://colab.research.google.com/github/google/seqio/blob/main/seqio/notebooks/Basics_Evaluation.ipynb\" target=\"_parent\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/\u003e\u003c/a\u003e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOaHYOJmFdS5"
      },
      "outputs": [],
      "source": [
        "print(\"Installing dependencies...\")\n",
        "!pip install seqio-nightly\n",
        "\n",
        "import functools\n",
        "import numpy as np\n",
        "import seqio\n",
        "import scipy\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lknCVqDQZzDK"
      },
      "source": [
        "This colab demonstrates how to use `seqio.Task` and `seqio.Evaluator` to carry out model evaluation. Defining metric functions and model functions are the two central pieces of this process. They need to be created and then associated with `seqio.Task` construction.\n",
        "\n",
        "Note: metric functions and model functions are defined at `Task` level, but one can still run evaluation on a `Mixture`. When you do that, SeqIO runs evaluation separately on each sub-task under the mixture, i.e., evaluating the metric-fns configured in each sub-task (this is different from the behavior when training  on a mixture, where SeqIO loads and samples from each sub-task and produces a single dataset of mixed data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPC8uXacWz7s"
      },
      "source": [
        "# s1. setup\n",
        "\n",
        "We start with a Task created in a previous [colab on Task and Mixtures](https://github.com/google/seqio/blob/main/seqio/notebooks/Basics_Task_and_Mixtures.ipynb), which already has three preprocessors defined.\n",
        "\n",
        "- `seqio.preprocessors.rekey`\n",
        "- custom preprocessor: `sample_from_answers`\n",
        "- `seqio.preprocessors.tokenize` using `seqio.SentencePieceVocabulary`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gc8IGkeqxfEr"
      },
      "outputs": [],
      "source": [
        "# seqio.map_over_dataset is decorator to map decorated function \n",
        "# (e.g., sample_from_answers below) over all examples in a dataset.\n",
        "# for details, please refer to seqio.map_over_dataset() documentation.\n",
        "@seqio.map_over_dataset(num_seeds=1)\n",
        "def sample_from_answers(x, seed):\n",
        " answers = x['targets']\n",
        " sample_id = tf.random.stateless_uniform([],\n",
        "                                         seed=seed,\n",
        "                                         minval=0,\n",
        "                                         maxval=len(answers),\n",
        "                                         dtype=tf.int32)\n",
        " x['targets'] = answers[sample_id]\n",
        " return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VYYNh5SGhGI"
      },
      "outputs": [],
      "source": [
        "sentencepiece_model_file = \"gs://t5-data/vocabs/cc_all.32000.100extra/sentencepiece.model\"\n",
        "vocab = seqio.SentencePieceVocabulary(sentencepiece_model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 57,
          "status": "ok",
          "timestamp": 1657658103795,
          "user": {
            "displayName": "Kehang Han",
            "userId": "01768769292922834817"
          },
          "user_tz": 420
        },
        "id": "Gugif2gBGRqv",
        "outputId": "288b1156-2a7b-4e39-897f-d649cf8fd5c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u003cseqio.dataset_providers.Task at 0x7ff12fab5430\u003e"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seqio.TaskRegistry.remove('my_simple_task')\n",
        "seqio.TaskRegistry.add(\n",
        "    'my_simple_task',\n",
        "    source=seqio.TfdsDataSource('natural_questions_open:1.0.0'),\n",
        "    preprocessors=[\n",
        "       functools.partial(\n",
        "           seqio.preprocessors.rekey,\n",
        "           key_map={\n",
        "               'inputs': 'question',\n",
        "               'targets': 'answer',\n",
        "               'answers': 'answer',\n",
        "           }),\n",
        "       sample_from_answers,\n",
        "       seqio.preprocessors.tokenize,\n",
        "   ],\n",
        "    output_features={\n",
        "        'inputs': seqio.Feature(vocabulary=vocab),\n",
        "        'targets': seqio.Feature(vocabulary=vocab),\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 10058,
          "status": "ok",
          "timestamp": 1657658118782,
          "user": {
            "displayName": "Kehang Han",
            "userId": "01768769292922834817"
          },
          "user_tz": 420
        },
        "id": "51qxEi2hYIPc",
        "outputId": "579683ce-790b-45dd-ee6c-3c844569eea7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'answers': array([b'Romi Van Renterghem.'], dtype=object),\n",
              "  'inputs': array([ 113,   19,    8, 3202,   16,   72,  145,   25,  214], dtype=int32),\n",
              "  'inputs_pretokenized': b'who is the girl in more than you know',\n",
              "  'targets': array([12583,    23,  4480,  9405,    49,   122,  6015,     5],\n",
              "        dtype=int32),\n",
              "  'targets_pretokenized': b'Romi Van Renterghem.'}]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "task = seqio.TaskRegistry.get('my_simple_task')\n",
        "ds = task.get_dataset(sequence_length=None, split=\"train\", shuffle=False)\n",
        "list(ds.take(1).as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sKCsbBFY6So"
      },
      "source": [
        "# s2. define metric functions\n",
        "\n",
        "Currently `seqio` supports two types of metric functions.\n",
        "\n",
        "- Type 1: metric depending on model predictions (i.e., model output sequence)\n",
        "- Type 2: metric depending on model scores (i.e., log probability/likelihood of target sequence given input sequence)\n",
        "\n",
        "We will define one for each type below.\n",
        "\n",
        "- `sequence_accuracy()` belongs to Type 1 -  computing the accuracy of model output sequences matching the correponding target sequences.\n",
        "- `log_likelihood()` belongs to Type 2 - computing average log likelihood of target sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDpHgTtrYDcj"
      },
      "outputs": [],
      "source": [
        "def sequence_accuracy(targets, predictions):\n",
        " seq_acc = 100 * np.mean([p == t for p, t in zip(predictions, targets)])\n",
        " return {\"sequence_accuracy\": seq_acc}\n",
        "\n",
        "def log_likelihood(targets, scores):\n",
        " log_likelihood = np.mean([scipy.special.logsumexp(el) for el in scores])\n",
        " return {\"log_likelihood\": log_likelihood}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6poDGIGneQ8p"
      },
      "source": [
        "We supply these two metric_fns to the Task via `metric_fns` argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 56,
          "status": "ok",
          "timestamp": 1657658178512,
          "user": {
            "displayName": "Kehang Han",
            "userId": "01768769292922834817"
          },
          "user_tz": 420
        },
        "id": "YqTjloJTYFGA",
        "outputId": "e4777cb4-6594-4df2-9d26-f98484fce77b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u003cseqio.dataset_providers.Task at 0x7ff1270145e0\u003e"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seqio.TaskRegistry.remove('my_simple_task')\n",
        "seqio.TaskRegistry.add(\n",
        "    'my_simple_task',\n",
        "    source=seqio.TfdsDataSource('natural_questions_open:1.0.0'),\n",
        "    preprocessors=[\n",
        "       functools.partial(\n",
        "           seqio.preprocessors.rekey,\n",
        "           key_map={\n",
        "               'inputs': 'question',\n",
        "               'targets': 'answer',\n",
        "               'answers': 'answer',\n",
        "           }),\n",
        "       sample_from_answers,\n",
        "       seqio.preprocessors.tokenize,\n",
        "   ],\n",
        "    output_features={\n",
        "        'inputs': seqio.Feature(vocabulary=vocab),\n",
        "        'targets': seqio.Feature(vocabulary=vocab),\n",
        "    },\n",
        "    metric_fns=[sequence_accuracy, log_likelihood]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi8Wu7A8edAE"
      },
      "source": [
        "# s3. define model functions\n",
        "\n",
        "Now we define model functions that return model outputs so that metric functions can take in and compute the metrics.\n",
        "\n",
        "Currently, we only need two types of model outputs: predictions and scores (i.e., log probability/likelihood of target sequence given input sequence). We will have\n",
        "\n",
        "- `dummy_predict_fn` to produce predictions\n",
        "- `dummy_score_fn` to produce scores\n",
        "\n",
        "Note: in real world applications, standard modeling frameworks such as T5X support SeqIO evaluator. Specifically, users provide model functions defined in those modeling frameworks for seqio. At eval time, modeling framework invokes SeqIO evaluator and reports metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6R3YMzZGnS8"
      },
      "outputs": [],
      "source": [
        "def dummy_predict_fn(ds):\n",
        " return [(i, d['decoder_target_tokens']) for i, d in ds]\n",
        "\n",
        "def dummy_score_fn(ds):\n",
        " return [(i, 0.4) for i, d in ds]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4xK2YinJSkv"
      },
      "source": [
        "We construct a seqio evaluator that's tied to the task we'd like to evaluate on, which ensures we are getting data from the desired task. Concretely, the evaluator loads the data and convert it into the format model functions expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4ZdM__lGnpH"
      },
      "outputs": [],
      "source": [
        "evaluator = seqio.Evaluator(\n",
        "   mixture_or_task_name='my_simple_task',\n",
        "   feature_converter=seqio.EncDecFeatureConverter(pack=False),\n",
        "   eval_split='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXB0yEihJkaO"
      },
      "source": [
        "We supply `dummy_predict_fn` and `dummy_score_fn` to the `evaluator.evaluate()` so that evaluator can call to get `predictions` and `scores` for metric computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cnhbAyCHUtf"
      },
      "outputs": [],
      "source": [
        "metrics, _, _ = evaluator.evaluate(\n",
        "   compute_metrics=True,\n",
        "   step=None,\n",
        "   predict_fn=dummy_predict_fn,\n",
        "   score_fn=dummy_score_fn)\n",
        "\n",
        "print(metrics.result())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB5YuQX4IQGa"
      },
      "source": [
        "# s4. add postprocess_fn (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeikikHbRkHy"
      },
      "source": [
        "Sometimes we need carry out certain processing for predictions and targets. Here's where `postprocessor_fn` comes in handy. It runs on each target and prediction seperately before `metric_fn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oncI7rU-HXI3"
      },
      "outputs": [],
      "source": [
        "def gather_answers(target_or_pred, example, is_target):\n",
        "  if not is_target:\n",
        "    return target_or_pred\n",
        "  return [a.decode() for a in example[\"answers\"]]\n",
        "\n",
        "def multi_target_sequence_accuracy(targets, predictions):\n",
        "  # targets is a list of lists.\n",
        "  seq_acc = 100 * np.mean([p in t for p, t in zip(predictions, targets)])\n",
        "  return {\"multi_target_sequence_accuracy\": seq_acc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 57,
          "status": "ok",
          "timestamp": 1657660887747,
          "user": {
            "displayName": "Kehang Han",
            "userId": "01768769292922834817"
          },
          "user_tz": 420
        },
        "id": "w2YjeL9G3eda",
        "outputId": "1c97f995-14a2-4c52-9f9d-4d7fb7e8b22b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u003cseqio.dataset_providers.Task at 0x7ff127268670\u003e"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seqio.TaskRegistry.remove('my_simple_task')\n",
        "seqio.TaskRegistry.add(\n",
        "    'my_simple_task',\n",
        "    source=seqio.TfdsDataSource('natural_questions_open:1.0.0'),\n",
        "    preprocessors=[\n",
        "       functools.partial(\n",
        "           seqio.preprocessors.rekey,\n",
        "           key_map={\n",
        "               'inputs': 'question',\n",
        "               'targets': 'answer',\n",
        "               'answers': 'answer'\n",
        "           }),\n",
        "       sample_from_answers,\n",
        "       seqio.preprocessors.tokenize,\n",
        "   ],\n",
        "    output_features={\n",
        "        'inputs': seqio.Feature(vocabulary=vocab),\n",
        "        'targets': seqio.Feature(vocabulary=vocab),\n",
        "    },\n",
        "    postprocess_fn=gather_answers,\n",
        "    metric_fns=[multi_target_sequence_accuracy]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrU3j4wE4RYt"
      },
      "outputs": [],
      "source": [
        "evaluator = seqio.Evaluator(\n",
        "   mixture_or_task_name='my_simple_task',\n",
        "   feature_converter=seqio.EncDecFeatureConverter(pack=False),\n",
        "   eval_split='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 22049,
          "status": "ok",
          "timestamp": 1657660924339,
          "user": {
            "displayName": "Kehang Han",
            "userId": "01768769292922834817"
          },
          "user_tz": 420
        },
        "id": "8e0uvQ6I4APM",
        "outputId": "d1563b21-6a35-40fd-e4b8-43a420df8026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'my_simple_task': {'multi_target_sequence_accuracy': 97.4792243767313}}\n"
          ]
        }
      ],
      "source": [
        "metrics, _, _ = evaluator.evaluate(\n",
        "   compute_metrics=True,\n",
        "   step=None,\n",
        "   predict_fn=dummy_predict_fn,\n",
        "   score_fn=dummy_score_fn)\n",
        "\n",
        "print(metrics.result())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {},
      "name": "[seqio basics] Evaluation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
